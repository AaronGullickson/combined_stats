# Reading and Writing Data

Students often get hung up at the start of a quantitative research project with the simple task of getting their data loaded into the statistical software package they are using. This is frequently a problem because data are distributed in inconsistent and often confusing ways by the agencies that release them. Knowing how to work with raw data on multiple platforms is an important skill in being able to quickly get up and running with the more important parts of your analysis. 

## The gold standard: plain text

The best data comes as plain text. Plain text files (also known as [ASCII](http://www.asciitable.com/) files), in contrast to binary files, are easily readable across any platform without special, usually proprietary software. When you write a doument in WordPad in Windows or TextEdit in OSX, you are writing a plain text file. When you write a document in Microsoft Word, you are writing a binary file. Plain text files are easily transportable across a variety of different program formats, take up less memory, and are better for tracking changes in version control systems. In a perfect world of open science, all data would be plain text, in order to improve its accessibility. 

Data in plain text files usually comes in one of two formats: comma-separated values (CSV) files or fixed-width files. In both cases, one line of text corresponds to an observation, or a row of data. The difference between the two formats is how to distinguish the values for different variables within a line of text (i.e. the columns). 

### Working with CSV files

In a comma-separated values format, the columns in the data are separated by commas. Here is an example with a very small CSV data file named "data.csv".

```{r engine='bash', echo=FALSE, comment=""}
less resources/data.csv
```

There are a couple of things to note here about the format. First, the top line is the "header" line that gives the names of the variables. Its important for your statistical program to know whether the data file has a header line or not in order to properly process the file. Second, notice that character strings representing category labels are surrounded by quotes. This is good practice because character strings may sometimes include commas within them, as the location variable does in this case, and the program will treat that as a delimiter if not surrounded by quotation marks.  

We can read this data into R with the `read.csv` command:

```{r}
mydata <- read.csv("resources/data.csv", header=TRUE, sep=",")
mydata
```

TODO: Discuss the issue of paths to files

In truth, the command `read.csv("resources/data.csv")` would have worked equally well, because by default, the header option is true and the `sep` argument is ",". The `sep` command provides the character that serves to separate or delimit the variables, Thus it is often called the "delimiter". The use of the comma as the delimiter has become commmonplace, but is possible to specify another character as the delimiter. The second most common delimiter is the use of the tab ("\t" in R speak). Here is the same data as above, but this time separated by tabs and named "data_tab.txt":

```{r engine='bash', echo=FALSE, comment=""}
less resources/data_tab.txt
```

I can read it in using the same command as before but with "\t" as the separator:

```{r}
mydata <- read.csv("resources/data_tab.txt", header=TRUE, sep="\t")
mydata
```

In actuality, `read.csv` is just a wrapper function for a more complex function called `read.table`. If you access the help file for `read.table`, you will see that there are many different arguments for dealing with specific problems that might arise in your dataset. Lets say for example that I had a data file saved as "data_messy.csv" that looked like this:

```{r engine='bash', echo=FALSE, comment=""}
less resources/data_messy.csv
```

There are several complications here. First, there are a couple of comment lines at the top where the comment symbol is "*" that I don't want to get processed. I could handle this with either the `skip` option to skip a certain number of rows before reading the data , or the `comment.char` option to define what lines to skip by what character they start with. Second, there is a line above the proper headers with a description of each variable. I could use the `skip` option here again to skip this line. Finally, the lower-case "na" won't be recognized by default as a missing value by R, but the option `na.strings` will allow me to specify that is should. All together, I use the command:  

```{r}
mydata <- read.table("resources/data_messy.csv", sep=",",
                     header=TRUE, comment.char="*", skip=3,na.strings="na",
                     row.names=1, as.is=2)
mydata
summary(mydata$location)
summary(mydata$race)
```
Note that because I used the `skip=3` the use of the `comment.char` option here is redundant. I also added two more options that were useful. First, instead of recording the first column of names as a variable, I told `read.table` to treat the first column as the name of the row, so the row names show up as the name of the respondent. Second, the `as.is` option tells R to treat the location character strings as strings rather than converting them to factors, which is the default behavior. You can see the difference in the summary commands. 

You can also use the `read.csv` command to read in a dataset that you have constructed in spreadsheet software like Excel. If you use the "Save as.." option in Excel, one of the choices will be to save as a CSV file. Files created using this syntax in Excel can usually be read with no problems by `read.csv`. 

### Working with fixed-width text files

The second form that data in text format can take is "fixed-width" format where the specific length of each variable in terms of the number of characters is specified. For example, here is the same dataset in fixed-width format, saved as "data_fw.txt":

```{r engine='bash', echo=FALSE, comment=""}
less resources/data_fw.txt
```

Notice that the actual starting location of each variable is the same within each row. If you count the characters up, you will see that the first variable has a width of 5 characters, the second variable has a width of 10 characters, and so on.  We can use the `read.fwf` command by feeding in these variable widths. Note that this file does not contain headers, because the `read.fwf` command we will use has some issues with reading them in.

```{r}
mydata <- read.fwf("resources/data_fw.txt", widths=c(5,10,5,6,2), header=FALSE)
colnames(mydata) <- c("name","location","race","gender","yrsed")
mydata
```

The `colnames` command manually assigns the variable names for my data after the data are loaded. 

Data that has been recorded in fixed width format will also generally come with some documentation providing the width of starting and ending indices for each variable. Frequently, it will also include scripts showing you how to load the text data into different programs.

## Data in binary format

As a result of initiatives to make science more open, data is increasingly becoming available in simple text format, which improves its portability and accessibility. However, there are still many cases where data is available in a binary format that is readable only by a specific statistical software program. For example, the [quick download](https://gssdataexplorer.norc.org/pages/show?page=gss%2Fgss_data) page for the General Social Survey provides the comprehensive GSS data files but only in Stata and SPSS formats. Thats fine if you have purchased that software, but you are out of luck if you have not. This approach is Bad For Science, but you will still run into it quite a bit.  

Luckily, R can usually still read those files. The traditional way to do this is through a very useful add-on library called [`foreign`](https://cran.r-project.org/web/packages/foreign/foreign.pdf). This library has `read.dta`, `read.spss`, and `read.xport` commands to read in Stata, SPSS, and SAS datasets, respectively. It also can read in a few other formats, and can also write out datasets to Stata using the `write.dta` command. 

This is our first introduction to add-on libraries in R. The richness of the various add-on libraries are one of the great strengths of R. They are also easy to install. You can (and should) install the `foreign` library with the command `install.packages("foreign")`. Once it is installed, you can load the library with the command `library(foreign)`. This will give you access to all the commands in the library. 

Unfortunately, because of major re-structuring to Stata, the `read.dta` will only read Stata files created on version 12 or earlier. To read in more recent versions of Stata datasets, you need to use a newer library called `readstata13`, which you can install in the same fashion as `foreign`. 

To test these libraries out, I have loaded the data exampleI have been using into Stata and saved it as a binary stata dataset (\*.dta). I saved a version using the old Stata 12 format as "data_old.dta". 


I should be able to open up R and load those Stata datasets in with the `foreign` and `readstata13` libraries.

```{r}
library(foreign)
mydata <- read.dta("resources/data_old.dta")
mydata
library(readstata13)
mydata <- read.dta13("resources/data.dta")
mydata
summary(mydata)
```

Everything looks good except that because I didn't encode location and gender in Stata as categorical variables, those variables show up in R as character strings rather than factor variables. If I wanted to turn my either variable into a proper factor (categorical) variable, I can use the `factor` command:

```{r}
mydata$gender <- factor(mydata$gender)
summary(mydata$gender)
```

## Saving data

R has its own binary format for keeping track of data. You can save any object or set of objects to your filesystem with the `save` command. This will save a file in a binary \*.RData format. These objects can then be loaded back into R with the `load` command: 

```{r}
save(mydata, file="resources/data.RData")
load("resources/data.RData")
mydata
```

You can (and should) also save your data in CSV format with the `write.csv` or `write.table` function in R. When using `write.csv` I recommend always specifying `row.names=FALSE` or you will get an extra row relative to variable headers in your resulting CSV file. This will cause problems if you then try to read it back into R. 

```{r}
write.csv(mydata, row.names=FALSE, file="resources/mydata_R.csv")
```

```{r engine="bash", comment="", echo=FALSE}
less resources/mydata_R.csv
```